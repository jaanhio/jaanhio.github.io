<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>jaanhio</title>
    
    
    
    <link>/</link>
    <description>Recent content on jaanhio</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Oct 2021 20:25:08 +0800</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Debugging containers using nsenter</title>
      <link>/blog/nsenter-debug/</link>
      <pubDate>Mon, 11 Oct 2021 20:25:08 +0800</pubDate>
      
      <guid>/blog/nsenter-debug/</guid>
      <description>
        
          
          
          
        
        
        
          If you have ever managed a Kubernetes cluster, chances are you have encountered pods that just doesn&amp;rsquo;t want to behave the way they are supposed to.
You checked the logs and traced it back to the source code. Logic checks out :white_check_mark:
You started narrowing down the causes. Networking issue? Configuration issue?
You entered the container and decided to use ping to identify network connectivity issues.
/ $ ping google.com PING google.
          
        
        </description>
    </item>
    
    <item>
      <title>Visualizing alerts metrics on Grafana</title>
      <link>/blog/visualizing-alerts-metrics-grafana/</link>
      <pubDate>Sun, 26 Sep 2021 13:44:24 +0800</pubDate>
      
      <guid>/blog/visualizing-alerts-metrics-grafana/</guid>
      <description>
        
          
          
          
        
        
        
          When it comes to Prometheus and alerts, the typical use case is to send alerts to Alertmanager for handling (deduplication, grouping) and routing them to the various services such Slack, PagerDuty etc.
However, there might be situations where we might need to perform analysis on alert patterns and being able to visualize how often the alerts are firing can be very useful.
In this post, I will share how we can visualize the alert metrics on Grafana using the various PromQL operators and functions.
          
        
        </description>
    </item>
    
    <item>
      <title>Debugging a misfiring Prometheus alert</title>
      <link>/blog/debugging-prometheus-alert/</link>
      <pubDate>Mon, 20 Sep 2021 11:46:24 +0800</pubDate>
      
      <guid>/blog/debugging-prometheus-alert/</guid>
      <description>
        
          
          
          
        
        
        
          Last week at work, I encountered an alert that was misfiring. Or so I thought...
          
        
        </description>
    </item>
    
    <item>
      <title>Nodejs application CPU profile analysis with Flame Graphs</title>
      <link>/blog/nodejs-flamegraph-analysis/</link>
      <pubDate>Mon, 06 Sep 2021 22:03:43 +0800</pubDate>
      
      <guid>/blog/nodejs-flamegraph-analysis/</guid>
      <description>
        
          
          
          
        
        
        
          In my previous post, I shared about my debugging process using various Linux tools and debugger. During the process, I came across the analysis technique using flame graphs and thought it will be interesting to see what information I can get out of it.
 What are flame graphs? Flame graphs, as the name suggests, are graphs that look like flames because of the shape and color (usually red-yellowish hues). It was invented by Brendan Gregg for the purpose of analyzing performance issue and understand CPU usage quickly.
          
        
        </description>
    </item>
    
    <item>
      <title>Debugging high CPU usage and memory leak on Nodejs application</title>
      <link>/blog/debugging-nodejs-app/</link>
      <pubDate>Sat, 04 Sep 2021 15:28:44 +0800</pubDate>
      
      <guid>/blog/debugging-nodejs-app/</guid>
      <description>
        
          
          
          
        
        
        
          Recently one of our nodejs application (responsible for scraping metrics for external services) running in our EKS cluster was experiencing high CPU usage and memory leak and I was tasked to figure out the root cause. In this post, I will share my troubleshooting process and interesting stuff I discovered along the way.
It all began with an alert notifying us of the application experiencing CPU throttling. Looking at the dashboard, it became apparent that high CPU usage isn&amp;rsquo;t the only issue; it was also experiencing memory leak and oddly high incoming and outgoing traffic.
          
        
        </description>
    </item>
    
    <item>
      <title>Understanding the differences between alertmanager&#39;s group_wait, group_interval and repeat_interval</title>
      <link>/blog/understanding-alertmanager/</link>
      <pubDate>Fri, 27 Aug 2021 12:07:56 +0800</pubDate>
      
      <guid>/blog/understanding-alertmanager/</guid>
      <description>
        
          
          
          
        
        
        
          Alertmanager is an application that handles alerts sent by client applications such as Prometheus. It can also perform alert grouping, deduplication, silencing, inhibition. Definitely a useful addition to any modern monitoring infrastructure.
That being said, configuring it can be a little daunting with the many different configurations available and somewhat vague explanations on some of the terms.
While configuring Alertmanager, I came across these 3 confusing terms: group_wait, group_interval and repeat_interval.
          
        
        </description>
    </item>
    
    <item>
      <title>Node-exporter setup with Systemd</title>
      <link>/blog/linux-node-exporter-setup/</link>
      <pubDate>Thu, 19 Aug 2021 22:22:18 +0800</pubDate>
      
      <guid>/blog/linux-node-exporter-setup/</guid>
      <description>
        
          
          
          
        
        
        
          For those who aren&amp;rsquo;t familiar, node-exporter is a Prometheus exporter that exposes hardware and OS metrics from *NIX kernels.
To get it up and running, there&amp;rsquo;s a simple guide on Prometheus official docs. The issue with the approach is that running node-exporter by executing binary directly isn&amp;rsquo;t the most reliable approach in a production environment as there&amp;rsquo;s no way to ensure that the node_exporter process will run continuously.
This is where systemd comes in.
          
        
        </description>
    </item>
    
    <item>
      <title>Amwkdnuwad</title>
      <link>/amiwefnivmwe/dawjdnawdna/</link>
      <pubDate>Fri, 13 Aug 2021 09:03:30 +0800</pubDate>
      
      <guid>/amiwefnivmwe/dawjdnawdna/</guid>
      <description>
        
          
          
          
        
        
        
          OH nice you found me :)
          
        
        </description>
    </item>
    
    <item>
      <title>About me</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>
        
          
          
          
        
        
        
          Hello there! My name is Jianhao and I am a software engineer based in Singapore.
I am interested in all things about systems reliability, automation, performance (big fan of Brendan Gregg) and believe that a product is only as good as how reliable it is for its users.
This is where I write about my learnings and interesting finds and serves as my HA knowledge dumping ground.
Also a Marvel fan, food lover, competitive swimmer/lifesaver, aquascaper.
          
        
        </description>
    </item>
    
    <item>
      <title>Collection</title>
      <link>/collection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/collection/</guid>
      <description>
        
          
          
          
        
        
        
          A collection of interesting learning resources and tools I found.
          
        
        </description>
    </item>
    
  </channel>
</rss>